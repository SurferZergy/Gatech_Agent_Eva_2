[hyper]  # hyper-parameter of vanilla A2C => '~/monopoly_simulator/vanilla_A2C_main_v4.py'
print_interval = 100
learning_rate = 0.0002
gamma = 0.98
n_train_processes = 5
update_interval = 5
max_train_steps = 300
hidden_state = 256
action_space = 2
state_num = 90
actor_loss_coefficient = 1
save_path = '/weights'
num_test = 100  #number of test games in the test process


[env]  # hyper-parameter of environment => '~/env/monopoly_world.py'
num_active_players = 4
log_path = '/KG-rule/game_log.txt'  # File Path put the game simulation logging info
kg_save_interval = 10  # step of saving rule learning knowledge graph, not updating!!!!
initial_cash = 500  # Initial cash of this game
novelty_inject_num = 10  # The game rounds to inject novelty
rule_change_path = '/KG-rule/Rule_change.txt'  # A file to record rule change, just for visualization and debugging
kg_rel_path = '/KG-rule/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())

[kg]  # hyper-parameter of knowledge graph => '~/KG-rule/openie_triple.py'
jsonfile = '/KG-rule/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())
update_interval = 10  # step of updating rule learning knowledge graph
detection_num = 1500  # Novelty detection begins here for history recording
history_update_interval = 300  # Novelty detection interval for history recording

[matrix] # hyper-parameter of knowledge graph transition into matrix => '~/KG-rule/openie_triple.py'
entity_num = 40  # num of property
action_num = 40  # num of relations
matrix_folder= '/KG-rule/matrix_rule'  # folder storing matrix
vector_file = '/KG-rule/vector.npy'  # numpy file of vector generated from rule learning

[novelty]
percentage_var = 0.05  # the confidence interval of ks test for history recording

[server]
kg_rel_path = '/A2C_agent/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())
rule_change_path = '/A2C_agent/log/Rule_change.txt'