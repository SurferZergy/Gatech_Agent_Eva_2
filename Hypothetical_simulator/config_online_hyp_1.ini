[hyper]
print_interval = 1000
max_train_steps = 500000
num_test = 200  #number of test games in the test process
learning_rate = 0.0001
gamma = 0.99
n_train_processes = 2
update_interval = 5
hidden_state = 256
action_space = 2
state_num = 92
actor_loss_coefficient = 1
save_path = '/media/becky/GNOME-p3/monopoly_simulator_background/weights'

[env]  # hyper-parameter of environment => '~/env/monopoly_world.py'
num_active_players = 2  # number of players in this game. For training purpose, we prefer 2.
log_path = '/KG_rule/game_log_hyp_1.txt'  # File Path put the game simulation logging info
kg_save_interval = 5  # step of saving rule learning knowledge graph, not updating!!!!
initial_cash = 500  # Initial cash of this game
novelty_inject_num = 0 # The time of game rounds to inject novelty => 20 means adding novelty after simulating 20 games
rule_change_path = '/KG_rule/Rule_change_hyp_1.txt'  # A file to record rule change, just for visualization and debugging
kg_rel_path = '/KG_rule/json_kg_hyp_1.pickle'  # json file storing rule learning knowledge graph (type: dict())
;saved_gameboard_path = '/Hypothetical_simulator/game_board/current_gameboard_state.json'

[kg]  # hyper-parameter of knowledge graph => '~/KG_rule/openie_triple.py'
jsonfile = '/KG_rule/json_kg_baseline.pickle'  # json file storing rule learning knowledge graph (type: dict())
update_interval = 20  # step of updating rule learning knowledge graph
detection_num = 1500  # Novelty detection begins here for history recording
history_update_interval = 300  # Novelty detection interval for history recording

[matrix] # hyper-parameter of knowledge graph transition into matrix => '~/KG_rule/openie_triple.py'
entity_num = 40  # num of property
action_num = 40  # num of relations
matrix_folder= '/KG_rule/matrix_rule'  # folder storing matrix
vector_file = '/KG_rule/vector.npy'  # numpy file of vector generated from rule learning

[novelty]
percentage_var = 0.05  # the confidence interval of ks test for history recording