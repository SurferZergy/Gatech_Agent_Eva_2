[hyper]  # hyper-parameter of vanilla A2C => '~/monopoly_simulator/vanilla_A2C_main_v4.py'
print_interval = 10000
learning_rate = 0.0002, 0.05
gamma = 0.98
n_train_processes = 1
update_interval = 5
max_train_steps = 300000
hidden_state = 256
action_space = 2
state_num = 246
actor_loss_coefficient = 1


[env]  # hyper-parameter of environment => '~/env/monopoly_world.py'
num_active_players = 2
log_path = '/monopoly_simulator/gameplay.log'  # File Path put the game simulation logging info
kg_save_interval = 200  # step of saving rule learning knowledge graph, not updating!!!!
initial_cash = 500  # Initial cash of this game
novelty_inject_num = 200  # The game rounds to inject novelty
rule_change_path = '/KG-rule/Rule_change.txt'  # A file to record rule change, just for visualization and debugging

[kg]  # hyper-parameter of knowledge graph => '~/KG-rule/openie_triple.py'
jsonfile = '/KG-rule/json_kg.json'  # json file storing rule learning knowledge graph (type: dict())
update_interval = 100  # step of updating rule learning knowledge graph
detection_num = 15000  # Novelty detection begins here for history recording
history_update_interval = 3000  # Novelty detection interval for history recording

[matrix] # hyper-parameter of knowledge graph transition into matrix => '~/KG-rule/openie_triple.py'
entity_num = 40  # num of property
action_num = 40  # num of relations
matrix_folder= '/KG-rule/matrix_rule'  # folder storing matrix
vector_file = '/KG-rule/vector.npy'  # numpy file of vector generated from rule learning

[novelty]
percentage_var = 0.05  # the confidence interval of ks test for history recording