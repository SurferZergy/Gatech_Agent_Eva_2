Process Process-1:
Traceback (most recent call last):
  File "/home/becky/.conda/envs/KG-A2C/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/becky/.conda/envs/KG-A2C/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/media/becky/GNOME-p3/monopoly_simulator/vanilla_A2C.py", line 74, in worker
    ob, reward, done, info = env.step_after_nochange(data)
  File "/media/becky/GNOME-p3/env/simulator_env/gym_simulator_env/envs/simple_monopoly.py", line 55, in step_after_nochange
    observation_space, reward, terminal, info = self.MonopolyWorld.next_after_nochange(action)
  File "/media/becky/GNOME-p3/env/monopoly_world.py", line 291, in next_after_nochange
    self.save_kg()
  File "/media/becky/GNOME-p3/env/monopoly_world.py", line 369, in save_kg
    self.kg.build_kg_file(self.log_path, level='rel', use_hash=True, update_interval=self.kg_save_interval)
  File "/media/becky/GNOME-p3/KG-rule/openie_triple.py", line 198, in build_kg_file
    self.build_matrix_dict()
  File "/media/becky/GNOME-p3/KG-rule/openie_triple.py", line 316, in build_matrix_dict
    index_sub = self.board_name.index(sub)
ValueError: 'Chest-Two' is not in list
self.kg_vector ===> [[  0.  60.   0.  60. 200.   0. 100.   0. 100. 120.   0. 140. 150. 140.
  160. 200. 180.   0. 180. 200.   0. 220.   0. 220. 240. 200. 260. 260.
  150. 280.   0. 300. 300.   0. 320. 200.   0. 350. 100. 400.]
 [  0.   1.   2.   3.   4.   0.   6.   7.   8.   9.   0.  11.  12.  13.
   14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.
   28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.]
 [  0.   2.   0.   4.   0.   0.   6.   0.   6.   8.   0.  10.   0.  10.
   12.   0.  14.   0.  14.  16.   0.  18.   0.  18.  20.   0.  22.  22.
    0.  24.   0.  26.  26.   0.  28.   0.   0.  35.   0.  50.]
 [  0.   4.   0.   8.   0.   0.  12.   0.  12.  16.   0.  20.   0.  20.
   24.   0.  28.   0.  28.  32.   0.  36.   0.  36.  40.   0.  44.  44.
    0.  48.   0.  52.  52.   0.  56.   0.   0.  70.   0. 100.]]
loss_train ===> tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)
Step # :0, avg score : -0.348
Step # :0, avg winning : 0.000
loss_train ===> tensor(14.1235, device='cuda:0', grad_fn=<DivBackward0>)
Step # :1000, avg score : -3.327
Step # :1000, avg winning : 0.000
loss_train ===> tensor(21.1551, device='cuda:0', grad_fn=<DivBackward0>)
Step # :2000, avg score : -3.296
Step # :2000, avg winning : 0.000
loss_train ===> tensor(30.1292, device='cuda:0', grad_fn=<DivBackward0>)
Step # :3000, avg score : -2.342
Step # :3000, avg winning : 0.000
loss_train ===> tensor(23.1281, device='cuda:0', grad_fn=<DivBackward0>)
Step # :4000, avg score : -2.342
Step # :4000, avg winning : 0.000
Traceback (most recent call last):
  File "vanilla_A2C_main_v3.py", line 233, in <module>
    trainer.train()
  File "vanilla_A2C_main_v3.py", line 149, in train
    s_prime, _, done, masked_actions = self.envs.step_after_nochange(a_tf)
  File "/media/becky/GNOME-p3/monopoly_simulator/vanilla_A2C.py", line 136, in step_after_nochange
    return self.step_wait()
  File "/media/becky/GNOME-p3/monopoly_simulator/vanilla_A2C.py", line 117, in step_wait
    results = [master_end.recv() for master_end in self.master_ends] #receive from worker_end #format???
  File "/media/becky/GNOME-p3/monopoly_simulator/vanilla_A2C.py", line 117, in <listcomp>
    results = [master_end.recv() for master_end in self.master_ends] #receive from worker_end #format???
  File "/home/becky/.conda/envs/KG-A2C/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/becky/.conda/envs/KG-A2C/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/becky/.conda/envs/KG-A2C/lib/python3.7/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
